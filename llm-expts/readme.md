# Guide to code, data, and results for LLM experiments in UNIQORN

Below we provide a short guide to the various scripts and data used in the LLM experiments (zero-shot and RAG) for UNIQORN, and the result files they generated. The files are organized into topical directories, but we provide the short descriptions of what each file does, as a flat list below for easy reference. This should be helpful for reproducibility of the desired experiments. Note that the backend LLMs are constantly updated (espcially GPT-4o accessed via the API), so exact repeatability of the reported values is not guaranteed. But we expect overall trends of the experiments to hold good for some time. The original experiments were conducted in July 2024.

## Code

* general
    * prepare-data-kg-text.py: code to create merged data file for kg and text for dev QA pairs
    * prepare-data-kg.py: code to create merged QA data file for kg with questions, gold answers, rag contexts (triples) with bert from individual pickle and json files
    * prepare-data-text.py: code to create merged QA data file for text with questions, gold answers, rag contexts (snippets) with bert from individual pickle and json files
    * eval-llm-rag.py: code compares rag outputs with gpt4o/phi3 with gold answers via gpt4o
    * eval-llm-zero.py: code compares zero-shot outputs with gpt4o/phi3 with gold answers via gpt4o

* gpt4o
    * zero-gpt.py: code for generating zero-shot results with got4o
    * rag-gpt-kg-text.py: code for generating answers in rag setup by gpt4o over kg and text
    * rag-gpt-kg.py: code for generating answers in rag setup by gpt4o over kg
    * rag-gpt-text.py: code for generating answers in rag setup by gpt4o over text
    * check-hallu-gpt4o.py: code checks for hallucinations in gpt-4o outputs
    * perturb-gpt4o-matches.py: code to prepare synthetic data for stress-testing RAG, with passage perturbation
    * count-seqret.py: code counts how often "Seqret Uniquorn" is part of a generated answer in RAG (perturbation experiments) by gpt4o

* phi3
    * zero-phi.py: : code for generating zero-shot results with phi3    
    * rag-phi-kg-text.py: code for generating answers in rag setup by phi3 over kg and text
    * rag-phi-kg.py: code for generating answers in rag setup by phi3 over kg
    * rag-phi-text.py: code for generating answers in rag setup by phi3 over text

* uniqorn
    * prepare-uniqorn-rag-data.py: code to create merged data file with uniqorn answers for kg+text, kg, text
    * eval-llm-rag-uniqorn.py: code compares "rag" outputs with uniqorn (default uniqorn configuration) with gold answers via gpt4o

## Data

* dev-qa-pairs.json: The dev set of 1000 QA pairs

* top5-facts-kg.pkl: Contains the KG triples for each question in dev set in Python pickle format

* top5-snippets-text.pkl: Contains the text snippets for each question in dev set in Python pickle format

* merged-file-kg-text.json: Contains QA combined with KG triples and text snippets retrieved by BERT

* merged-file-kg.json: Contains QA combined with KG triples retrieved by BERT

* merged-file-text.json: Contains QA combined with text snippets retrieved by BERT

* merged-file-kg-text-perturbed.json: Contains QA combined with KG triples and text snippets retrieved by BERT, but gold answers have been replaced by "Seqret Uniquorn" in evidences

* merged-file-kg-perturbed.json: Contains QA combined with KG triples retrieved by BERT, but gold answers have been replaced by "Seqret Uniquorn" in triples

* merged-file-text-perturbed.json: Contains QA combined with KG triples and text snippets retrieved by BERT, but gold answers have been replaced by "Seqret Uniquorn" in evidences

## Results

* gpt4o
    * generated answers
        
        * answers-gpt4o-zero.json: Zero-shot answers by gpt4o
        
        * answers-gpt4o-rag-kg-text.json: RAG answers by gpt4o over KG and text
        * answers-gpt4o-rag-kg.json: RAG answers by gpt4o over text
        * answers-gpt4o-rag-text.json: RAG answers by gpt4o over text 

        * answers-gpt4o-rag-kg-text-perturbed.json: RAG answers by gpt4o over KG and text in passage perturbation experiments
        * answers-gpt4o-rag-kg-perturbed.json: RAG answers by gpt4o over KG in passage perturbation experiments
        * answers-gpt4o-rag-text-perturbed.json: RAG answers by gpt4o over text in passage perturbation experiments
        
        * answers-gpt4o-rag-kg-hallu.json: Sample of KG-RAG answers generated by gpt4o manually annotated for hallucinations
        * answers-gpt4o-rag-text-hallu.json: Sample of Text-RAG answers generated by gpt4o manually annotated for hallucinations

    * evaluation results (one can see evaluation metric at the bottom of each eval file)
        
        * eval-gpt4o-rag-kg-text.txt: Evaluation results of got4o in KG+Text RAG
        * eval-gpt4o-rag-kg.txt: Evaluation results of got4o in KG RAG
        * eval-gpt4o-rag-text.txt: Evaluation results of got4o in Text RAG
        
        * eval-gpt4o-rag-kg-text-perturbed.txt: Evaluation results of got4o in KG+Text RAG in passage perturbation setup
        * eval-gpt4o-rag-kg-perturbed.txt: Evaluation results of got4o in KG RAG in passage perturbation setup
        * eval-gpt4o-rag-text-perturbed.txt: Evaluation results of got4o in Text RAG in passage perturbation setup
        
        * eval-gpt4o-zero.txt: Evaluation results of got4o in zero-shot setup
    
    * matched cases with gold answers
        * matches-gpt4o-rag-kg-text-perturbed.json: Contains matches of generated answers with gold answers by gpt4o in RAG setup over KG+Text, in passage perturbation experiment
        * matches-gpt4o-rag-kg-text.json: Contains matches of generated answers with gold answers by gpt4o in RAG setup over KG+Text
        * matches-gpt4o-rag-kg.json: Contains matches of generated answers with gold answers by gpt4o in RAG setup over KG
        * matches-gpt4o-rag-text-perturbed.json: Contains matches of generated answers with gold answers by gpt4o in RAG setup over Text, in passage perturbation experiment
        * matches-gpt4o-rag-text.json: Contains matches of generated answers with gold answers by gpt4o in RAG setup over Text

* phi3
    * generated answers
        * answers-phi3-zero.json: Contains matches of generated answers with gold answers by phi3 in zero-shot setting
        * answers-phi3-rag-kg-text.json: Contains matches of generated answers with gold answers by phi3 in RAG setup over KG+Text
        * answers-phi3-rag-kg.json: Contains matches of generated answers with gold answers by phi3 in RAG setup over KG
        * answers-phi3-rag-text.json: Contains matches of generated answers with gold answers by phi3 in RAG setup over Text
    
    * evaluation results
        * eval-phi3-zero.txt: Evaluation results of phi3 in zero-shot setup
        * eval-phi3-rag-kg-text.txt: Evaluation results of phi3 in KG+Text RAG
        * eval-phi3-rag-kg.txt: Evaluation results of phi3 in KG RAG
        * eval-phi3-rag-text.txt: Evaluation results of phi3 in Text RAG
        
* uniqorn
    * retrieved answers
        * answers-uniqorn-rag-kg-text.json: Answers retrieved by UNIQORN in RAG (usual) setup over KG+Text
        * answers-uniqorn-rag-kg.json: Answers retrieved by UNIQORN in RAG (usual) setup over KG
        * answers-uniqorn-rag-text.json: Answers retrieved by UNIQORN in RAG (usual) setup over Text
    
    * evaluation results
        * eval-uniqorn-rag-kg-text.txt: Evaluation summary of UNIQORN answers in simulated RAG setup over KG+Text
        * eval-uniqorn-rag-kg.txt: Evaluation summary of UNIQORN answers in simulated RAG setup over KG
        * eval-uniqorn-rag-text.txt: Evaluation summary of UNIQORN answers in simulated RAG setup over Text

In case of questions, please contact Rishiraj Saha Roy (rishiraj dot saharoy at gmail dot com)
